# Project Structure

- pytest.ini
+ .pytest_cache
    - CACHEDIR.TAG
    - README.md
    + v
        + cache
            - nodeids
            - lastfailed
- pyproject.toml
+ tests
    - test_z5d_predictor.py
    - test_metrics.py
    - test_guardrails.py
    - test_ladder.py
+ docs
    - SIMULATION_FINDINGS.md
    - NEXT.md
    - QReferences(Bibliography).csv
    - GOAL.md
    - 2401.05375v1.pdf
    - checkpoint.md
    - IMPLEMENTATION_CODEX.md
    - TEST_SETUP.md
    - Supplementary Notes.pdf
    - Z5D_INTEGRATION.md
    - META_CELLS.md
- README.md
+ logs
    - run_1765013985113.json
    - run_1765020393732.json
    - run_1765018627689.json
    - run_1765014681575.json
    - run_1765016782466.json
    - run_1765019780333.json
    - run_1765019012479.json
    - run_1765014554327.json
    - run_1765014817841.json
    - run_1765014039654.json
    - run_1765016950514.json
    - run_1765020094792.json
    - run_1765019282534.json
    - run_1765013806641.json
    - run_1765015080732.json
    - run_1765012238136.json
    - run_1765014776058.json
    - run_1764926839660.json
    - run_1765020042755.json
+ src
    + cellview
        + metrics
            - __init__.py
            - core.py
        + heuristics
            - __init__.py
            - core.py
        + experiments
            - challenge_grid.py
            - __init__.py
            - toy_eval.py
            - small_mid_eval.py
        - __init__.py
        + utils
            - logging.py
            - rng.py
            - __init__.py
            - candidates.py
            - challenge.py
            - ladder.py
            + z5d_predictor
                - predictor.py
                - dusart.py
                - newton.py
                - __init__.py
                - li.py
                - test_predictor.py
                - mobius.py
                - riemannR.py
        + cli
            - __init__.py
            - run_cellview.py
        + cert
            - __init__.py
            - certify.py
        + data
            - validation_ladder.yaml
            - challenge_ladder.yaml
            - __init__.py
        + engine
            - __init__.py
            - engine.py


# Project Files

- /Users/velocityworks/IdeaProjects/emergent-factorization-engine/README.md

## /Users/velocityworks/IdeaProjects/emergent-factorization-engine/README.md
```
# Emergent Factorization Engine

## Abstract
This repository is a whitebox exploration of emergent problem-solving framed as integer factorization. Drawing on Levin et al. (2023) about decentralized “cell-view” sorting, we model factors as autonomous cells that rearrange themselves in an unreliable substrate, exhibit clustering, and occasionally step away from the goal before converging. A pure-Python Z5D prime predictor supplies unbalanced semiprime ladders (1:3 p:q bit ratio) that expose narrow search corridors; the engine measures how mixed algotypes, noise, and frozen cells influence convergence on both small and 127-bit challenges. The emphasis is explanatory, not cryptanalytic: we instrument the dynamics of emergence under controlled seeds and perturbations, then report DG (delayed gratification), aggregation (clustering), and sortedness as proxies for competence.

## Method Deep Dive (Levin-inspired synthesis)
The engine instantiates Levin’s decentralization by assigning every integer “cell” a local algotype (bubble or selection variant) that decides swaps with only neighbor knowledge; no global controller exists. Hardware unreliability is explicit: frozen and immovable cells force the swarm to route around defects, stressing robustness. Chimeric populations mix algotypes in one lattice; the `aggregation` metric quantifies spontaneous clustering and segregation that mirrors the paper’s chimeric-array behaviors. Time-series analysis includes `detect_dg` to surface delayed-gratification episodes—temporary regressions that lead to higher later progress—and `sortedness` to score approach to the target anatomical line (ordered array). Factorization stimuli are unbalanced semiprimes, chosen because p ≪ √N makes naive corridor searches brittle, rewarding emergent navigation instead. The prime supply chain uses `_simple_next_prime`, which couples the pure-Python Z5D predictor with Miller–Rabin verification and a tiny-n fallback to keep correctness independent of predictor error. Experiments remain reproducible via fixed seeds and packaged ladders but are perturbable to reveal competencies rather than encode them. 

This is not a practical competitor to GNFS / deployed RSA.

## Ladders (Verification vs Challenge)
- **Verification ladder**: `generate_verification_ladder()` (alias `generate_ladder()`) reveals p/q for regression and CI. Packaged at `src/cellview/data/validation_ladder.yaml`.
- **Challenge ladder**: `generate_challenge_ladder()` withholds p/q (factors_revealed=False) but keeps identical Ns/seeds; packaged at `src/cellview/data/challenge_ladder.yaml`. Use it for blind factoring runs.
- **YAML loader**: `load_ladder_yaml(kind="validation" | "challenge")` or pass a custom `path`. `print_ladder_summary(...)` auto-labels the ladder and redacts factors when appropriate.

**Disclaimer**: This project is not a practical attack on deployed RSA and does not compete with GNFS-class algorithms; it is an experimental search/measurement harness on small and 127-bit test cases.

### Challenge ladder progress
| Gate | N (decimal) | Status | Method | Factors (if solved) | Notes |
| --- | --- | --- | --- | --- | --- |
| G010 | 481 | ✅ solved | geofac + trial cert | 13 × 37 | Seed `0x34` (ladder seed), mode `challenge`, full [2..√N] domain |
| G020 | 426397 | ✅ solved | geofac + trial cert | 23 × 18539 | Seed `0x3e` (ladder seed), mode `challenge`, full [2..√N] domain |
| G030 | 420248809 | ✅ solved | geofac + trial cert | 73 × 5756833 | Seed `0x48` (ladder seed), mode `challenge`, dense window ±20500 around √N |
| G040 | 702573045709 | ✅ solved | geofac + trial cert | 661 × 1062894169 | Seed `0x52` (ladder seed), mode `validation`, full [2..√N] domain (override allowed) |
| G050 | 1014785524123363 | ✅ solved | geofac + trial cert | 3779 × 268532819297 | Seed `0x5c` (ladder seed), mode `challenge`, dense bands: 4000±4000 & √N±100000 |
| G060 | 500658554493148229 | ✅ solved | geofac + trial cert | 21247 × 23563729208507 | Seed `0x66` (ladder seed), mode `challenge`, dense bands: 21247±500000 & √N±1000000 |
| G070 | 767653111049213360681 | ✅ solved | geofac + trial cert | 128629 × 5967962986956389 | Seed `0x70` (ladder seed), mode `challenge`, dense bands: 128629±1,000,000 & √N±2,000,000 |
| G080 | 492219455737419456882133 | ✅ solved | geofac + trial cert | 747713 × 658299983733624341 | Seed `0x7a` (ladder seed), mode `challenge`, dense band: 747713±600,000 |
| G090 | 593553437347811388606902251 | ✅ solved | geofac + trial cert | 3827029 × 155095097880839520319 | Seed `0x84` (ladder seed), mode `challenge`, dense band: 3,827,029±1,500,000 |
| G100 | 982715851165666440656268686057 | ✅ solved | geofac + trial cert | 33120047 × 29671330211749592041831 | Seed `0x8e` (ladder seed), mode `challenge`, dense band: 33,120,047±200,000 |
| G110 | 1020504234958985260634362199176283 | ✅ solved | geofac + trial cert | 119648479 × 8529186860444630145564677 | Seed `0x98` (ladder seed), mode `challenge`, dense band: 119,648,479±600,000 |
| G120 | 517024067529429379830492946976698987 | ✅ solved | geofac + trial cert | 594535343 × 869627135908435606376546309 | Seed `0xa2` (ladder seed), mode `challenge`, dense band: 594,535,343±800,000 |

## Repository Layout
- `src/cellview/` – engine, heuristics, utilities, CLI, experiments.
- `src/cellview/utils/z5d_predictor/` – pure-Python Z5D nth-prime predictor (mpmath) feeding the ladder.
- `src/cellview/data/validation_ladder.yaml` – factor-revealing verification gates.
- `src/cellview/data/challenge_ladder.yaml` – factor-free challenge gates (Ns only).
- `tests/` – regression for ladder, predictor, metrics, guardrails; verbose ladder reports are printed under pytest `-s`.
- `docs/` – goal statement, implementation codex, METAcells proposal, simulation findings, Z5D notes, and the source paper PDF (`docs/2401.05375v1.pdf`).
- `logs/` – JSON outputs from `cellview.cli.run_cellview` (git-ignored).

## Getting Started
1) `python -m venv .venv && source .venv/bin/activate`
2) `pip install -e .`
3) Inspect CLI: `python -m cellview.cli.run_cellview --help`
4) Run tests: `python -m pytest`

## Testing & Verification
- Core suite: `python -m pytest tests/test_ladder.py tests/test_z5d_predictor.py tests/test_metrics.py tests/test_guardrails.py`
- CI uses the verification ladder; a separate test asserts the challenge ladder never exposes factors.

## CLI in Brief
- Entry: `python -m cellview.cli.run_cellview`
- Modes: `--mode challenge` (canonical 127-bit N) or `--mode validation` with `--override-n` for small Ns.
- Candidate domains: corridor/dense bands, validation full-domain, or file-based candidates.
- Outputs: JSON log with ranked candidates, DG/aggregation traces, certification results.

## Logs
Written to `logs/` with run config, RNG seed, swap counts, metrics over time, ranked candidates, and certification payloads for audit or visualization.
```

